An important type of scientific workload is quite easy to parallelize,
  * parameter exploration, i.e., running software on a data set with many
    different parameter settings;
  * running software on many different input files; or
  * a combination of the two scenarios above.

Since this workload is so common, we developed some frameworks to
support them, and take the bookkeeping burden of your shoulders as
much as possible: [worker](https://worker.readthedocs.io/en/latest/)
and [atools](https://atools.readthedocs.io/en/latest/).


# Learning outcomes

When you complete this training you will be able to

  * how to use the worker framework;
  * how to use atools;
  * have a good understanding of the situations in which worker
    or atools should be used;
  * are aware of potential pitfalls.


# Schedule

  | Time        | Subject                                                |
  |-------------|--------------------------------------------------------|
  | 09:00-09:15 | introduction and motivation |
  | 09:15-10:30 | worker framework |
  | 10:30-10:45 | coffee break |
  | 10:45-11:30 | atools |
  | 11:30-11:50 | use cases & comparison |
  | 11:50-12:00 | wrap up |

Slides are available in the
 [GitHub repository](https://github.com/gjbex/worker-and-atools/),
as well as example code and job scripts.


# Target audience

This training is for you if you need to use HPC resources effectively
for embarrassingly parallel workloads.


# Prerequisites

You will need to be comfortable using Linux and the HPC environment.
If necessary, attend the appropriate training sessions on those subjects.


# Trainer(s)

  * Geert Jan Bex ([geertjan.bex@uhasselt.be](mailto:geertjan.bex@uhasselt.be))
